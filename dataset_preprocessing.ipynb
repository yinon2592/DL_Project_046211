{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR+sW4pnQWMuHs68D4pSMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinon2592/DL_Project_046211/blob/main/dataset_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yedOYz_xZFPP",
        "outputId": "f04ca216-a34d-4936-dace-1e9ca6873ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-27 14:57:05--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/training.1600000.processed.noemoticon.csv.zip\n",
            "Resolving nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
            "Connecting to nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85088192 (81M) [application/zip]\n",
            "Saving to: ‘data/training.1600000.processed.noemoticon.csv.zip’\n",
            "\n",
            "training.1600000.pr 100%[===================>]  81.15M   109MB/s    in 0.7s    \n",
            "\n",
            "2023-06-27 14:57:06 (109 MB/s) - ‘data/training.1600000.processed.noemoticon.csv.zip’ saved [85088192/85088192]\n",
            "\n",
            "Archive:  data/training.1600000.processed.noemoticon.csv.zip\n",
            "  inflating: data/training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
        "!unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/my-drive/project_calculations')\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me5VB4ADecgJ",
        "outputId": "2dccc17d-e346-42c9-9201-25de865bf81a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Remove usernames\n",
        "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters\n",
        "    # Remove newlines and multiple whitespaces\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove special characters and punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "file_path=\"data/training.1600000.processed.noemoticon.csv\"\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['label', 'text']\n",
        "df = df[df['label'] != 2]\n",
        "df['label'] = df['label'].replace({4: 1})\n",
        "df.dropna(how='any', inplace=True)\n",
        "df = df.loc[df['text'].apply(lambda x: isinstance(x, str))]\n",
        "df = df.loc[df['label'].apply(lambda x: isinstance(x, int))]\n",
        "df['text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "EUa93qYsZSk3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of chunks\n",
        "num_chunks = 3\n",
        "\n",
        "# Shuffle the DataFrame rows randomly\n",
        "df_shuffled = df.sample(frac=1, random_state=42)\n",
        "\n",
        "# Split the shuffled DataFrame into chunks\n",
        "chunks = [df_shuffled[i::num_chunks] for i in range(num_chunks)]\n",
        "\n",
        "# Save the chunks as CSV files to Google Drive\n",
        "\n",
        "complete_cleaned_data_path = '/content/drive/My Drive/project_dataset/sentiment_140.csv'\n",
        "df.to_csv(complete_cleaned_data_path, index=False)\n",
        "\n",
        "section_a_data_path = '/content/drive/My Drive/project_dataset/section_a_data.csv'\n",
        "section_c_data_path = '/content/drive/My Drive/project_dataset/section_c_data.csv'\n",
        "test_data_path = '/content/drive/My Drive/project_dataset/test_data.csv'\n",
        "\n",
        "chunks[0].to_csv(section_a_data_path, index=False)\n",
        "chunks[1].to_csv(section_c_data_path, index=False)\n",
        "chunks[2].to_csv(test_data_path, index=False)\n",
        "\n",
        "print(\"Dataset chunks saved to Google Drive successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl8crjwoZiES",
        "outputId": "b2f06e28-ea0f-4cba-a01e-999a9338169f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset chunks saved to Google Drive successfully.\n"
          ]
        }
      ]
    }
  ]
}