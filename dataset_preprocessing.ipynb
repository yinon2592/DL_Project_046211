{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGJJE6eovJ4MXMOhGKnrWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinon2592/DL_Project_046211/blob/main/dataset_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yedOYz_xZFPP",
        "outputId": "73ca64ba-faf2-4037-934f-fbd659e34aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘data/training.1600000.processed.noemoticon.csv.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  data/training.1600000.processed.noemoticon.csv.zip\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
        "!unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/my-drive/project_calculations')\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me5VB4ADecgJ",
        "outputId": "c543c5ec-fa1e-4a87-ab20-e3d42b64d25e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Remove usernames\n",
        "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters\n",
        "    # Remove newlines and multiple whitespaces\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove special characters and punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "file_path=\"data/training.1600000.processed.noemoticon.csv\"\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['label', 'text']\n",
        "df = df[df['label'] != 2]\n",
        "df['label'] = df['label'].replace({4: 1})\n",
        "df = df.loc[df['text'].apply(lambda x: isinstance(x, str))]\n",
        "df = df.loc[df['label'].apply(lambda x: isinstance(x, int))]\n",
        "df['text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "EUa93qYsZSk3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of chunks\n",
        "num_chunks = 3\n",
        "\n",
        "# Shuffle the DataFrame rows randomly\n",
        "df_shuffled = df.sample(frac=1, random_state=42)\n",
        "\n",
        "# Split the shuffled DataFrame into chunks\n",
        "chunks = [df_shuffled[i::num_chunks] for i in range(num_chunks)]\n",
        "\n",
        "# Save the chunks as CSV files to Google Drive\n",
        "\n",
        "complete_cleaned_data_path = '/content/drive/My Drive/project_dataset/sentiment_140.csv'\n",
        "df.to_csv(complete_cleaned_data_path, index=False)\n",
        "\n",
        "section_a_data_path = '/content/drive/My Drive/project_dataset/section_a_data.csv'\n",
        "section_c_data_path = '/content/drive/My Drive/project_dataset/section_c_data.csv'\n",
        "test_data_path = '/content/drive/My Drive/project_dataset/test_data.csv'\n",
        "\n",
        "chunks[0].to_csv(section_a_data_path, index=False)\n",
        "chunks[1].to_csv(section_c_data_path, index=False)\n",
        "chunks[2].to_csv(test_data_path, index=False)\n",
        "\n",
        "print(\"Dataset chunks saved to Google Drive successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl8crjwoZiES",
        "outputId": "3c5b96c9-88e8-4c9f-f728-28a4d62f3844"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset chunks saved to Google Drive successfully.\n"
          ]
        }
      ]
    }
  ]
}