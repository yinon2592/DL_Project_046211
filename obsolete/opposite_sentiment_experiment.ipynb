{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN19Kc4uSV1FqKKJmTeVp8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinon2592/DL_Project_046211/blob/main/main_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/my-drive/project_calculations')\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Mmnnh7cMt2iM",
        "outputId": "d108a3f2-f385-472e-aea0-2dfda12c0abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **picking sentiment classifier**"
      ],
      "metadata": {
        "id": "aeSeSZy1bg5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj8qxFimIpZT",
        "outputId": "e05c23d7-6129-4102-c222-bfe08b7dfdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: Positive\n",
            "Sentiment Probabilities: [0.00012409620103426278, 0.9998759031295776]\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the pre-trained sentiment classification model and tokenizer\n",
        "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "sentiment_classifier_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "sentiment_classifier_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Text input for sentiment classification\n",
        "text = \"I really enjoyed the movie. It was fantastic!\"\n",
        "\n",
        "# Tokenize the text\n",
        "encoded_input = sentiment_classifier_tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "# Perform sentiment classification\n",
        "output = sentiment_classifier_model(**encoded_input)\n",
        "\n",
        "# Retrieve the predicted label and associated probabilities\n",
        "predicted_label = output.logits.argmax().item()\n",
        "predicted_probabilities = output.logits.softmax(dim=1).tolist()[0]\n",
        "\n",
        "# Map the predicted label to sentiment class\n",
        "sentiment_classes = [\"Negative\", \"Positive\"]\n",
        "predicted_sentiment = sentiment_classes[predicted_label]\n",
        "\n",
        "# Print the predicted sentiment and associated probabilities\n",
        "print(\"Predicted Sentiment:\", predicted_sentiment)\n",
        "print(\"Sentiment Probabilities:\", predicted_probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load 'sentiment140' Test Data**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "21d6jGdPb0jK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "# load test data (data already cleaned)\n",
        "test_data_path = '/content/drive/My Drive/project_dataset/test_data.csv'\n",
        "df = pd.read_csv(test_data_path)\n",
        "df = df.sample(10)\n",
        "df['generated_sentence'] = \"\""
      ],
      "metadata": {
        "id": "9NEISeJ3UK3b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **prompt engineer gpt2 to rephrase sentenses with opposite sentiment**"
      ],
      "metadata": {
        "id": "6KtbdhHGcaLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Model Loading\n",
        "model_name = 'gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 4: Sentence Generation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, row in df.iterrows():\n",
        "        sentiment = row['label']\n",
        "        opposite_sentiment = 'positive' if sentiment == 'negative' else 'negative'  # Determine the opposite sentiment\n",
        "        input_prompt = f\"rephrase the sentence to {opposite_sentiment} sentiment: {row['text']}\"\n",
        "        input_ids = tokenizer.encode(input_prompt, add_special_tokens=True, return_tensors='pt').to(device)\n",
        "\n",
        "        # Check if input_ids is not None and has a valid shape\n",
        "        if input_ids is not None and input_ids.shape[-1] > 0:\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=input_ids.ne(0),  # Pass attention mask to the model (assuming pad_token_id is 0)\n",
        "                max_length=100,\n",
        "                num_return_sequences=1,\n",
        "                pad_token_id=0  # Set pad_token_id to 0\n",
        "            )\n",
        "            generated_sentence = tokenizer.decode(generated_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "            df.at[i, 'generated_sentence'] = generated_sentence\n",
        "        else:\n",
        "            df.at[i, 'generated_sentence'] = \"\"  # Assign an empty string if input_ids is None or has shape (0, )\n",
        "\n",
        "# Print the generated sentences\n",
        "# print(df['generated_sentence'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4GxCxO1Q5Jj",
        "outputId": "9e32bfb1-10e8-4ccd-e65b-758bf7b1adf6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        label                                               text  \\\n",
            "338331      1                         take good care n rest well   \n",
            "442301      0  my ipod died so i cant finish my movie umm so ...   \n",
            "403006      0               elena lost today after a great fight   \n",
            "348506      1                     haha you make me laugh so much   \n",
            "213289      0  i m going back to bed cus i don t feel well ma...   \n",
            "99391       1                             i thought you d dig it   \n",
            "199485      1  watching ace ventura with the sis quality bond...   \n",
            "288263      1  that is really cute i thought about doing that...   \n",
            "126371      1  has a interview for an internship wed and one ...   \n",
            "51296       0  incredibly upset eddie s attic just announced ...   \n",
            "\n",
            "                                       generated_sentence  \n",
            "338331  .\\n\\nThe following is a list of the most commo...  \n",
            "442301   is over umm so i guess i dont have to sleep u...  \n",
            "403006   with her husband.\\n\\nThe woman, who is not na...  \n",
            "348506  .\\n\\nI'm not sure if this is a good idea or no...  \n",
            "213289   and i can't sleep i can't sleep i can't sleep...  \n",
            "99391   .\\n\\nThe first sentence is a bit of a misnomer...  \n",
            "199485  .\\n\\nThe same goes for the other two.\\n\\nThe f...  \n",
            "288263   and said \"I'm not going to do that\".\\n\\nI'm n...  \n",
            "126371   to work with you.\\n\\nThe first thing you need...  \n",
            "51296    for a while. i'm gonna be out of town for a w...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **check accuracy with sentiment classifier**"
      ],
      "metadata": {
        "id": "DppX4OOLcvWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store the accuracy values\n",
        "accuracies = []\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for i, row in df.iterrows():\n",
        "    original_sentence = row['text']\n",
        "    opposite_sentence = row['generated_sentence']\n",
        "\n",
        "    # Encode the original and opposite sentences\n",
        "    original_input = sentiment_classifier_tokenizer(original_sentence, truncation=True, padding=True, return_tensors='pt')\n",
        "    opposite_input = sentiment_classifier_tokenizer(opposite_sentence, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    # Get the input IDs and attention mask tensors\n",
        "    original_input_ids = original_input['input_ids'].to(device)\n",
        "    original_attention_mask = original_input['attention_mask'].to(device)\n",
        "    opposite_input_ids = opposite_input['input_ids'].to(device)\n",
        "    opposite_attention_mask = opposite_input['attention_mask'].to(device)\n",
        "\n",
        "    # Move the sentiment classification model to the desired device\n",
        "    sentiment_classifier_model = sentiment_classifier_model.to(device)\n",
        "\n",
        "    # Make predictions for the original and opposite sentences\n",
        "    with torch.no_grad():\n",
        "        original_outputs = sentiment_classifier_model(original_input_ids, attention_mask=original_attention_mask)\n",
        "        opposite_outputs = sentiment_classifier_model(opposite_input_ids, attention_mask=opposite_attention_mask)\n",
        "\n",
        "    # Get the predicted labels\n",
        "    original_predicted_label = torch.argmax(original_outputs.logits).item()\n",
        "    opposite_predicted_label = torch.argmax(opposite_outputs.logits).item()\n",
        "\n",
        "    # Check if the opposite rephrase has the opposite sentiment label\n",
        "    is_opposite = original_predicted_label != opposite_predicted_label\n",
        "\n",
        "    # Calculate accuracy and add it to the list\n",
        "    accuracy = 1 if is_opposite else 0\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "overall_accuracy = sum(accuracies) / len(accuracies)\n",
        "\n",
        "# Print the overall accuracy\n",
        "print(f\"Accuracy: {overall_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79A2nYwuYrxi",
        "outputId": "a94c57e4-c23e-41f3-9e1c-35d04d1ea71e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n"
          ]
        }
      ]
    }
  ]
}
