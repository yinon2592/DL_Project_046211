{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOAaHL1NyfjlMKc33wIpRLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinon2592/DL_Project_046211/blob/main/section_c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 599,
      "metadata": {
        "id": "VT4imDtYONBU"
      },
      "outputs": [],
      "source": [
        "# links : https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/my-drive/project_calculations')\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYaC1NOQORdJ",
        "outputId": "38dda7ec-d6ce-4bde-905b-d21a1f673853"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/project_calculations/section_c_model_description.txt'\n",
        "\n",
        "text_content = \"\"\"\n",
        "  train size : 8000\n",
        "  validation size : 2000\n",
        "  prompt : text = f'\\\"{txt}\\\" Q: between positive or negative what was the sentiment of the last text ? A:' + f'{sentiment}'\n",
        "  total_epochs = 2\n",
        "  model type: 'gpt2-large'\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(text_content)"
      ],
      "metadata": {
        "id": "HNw03k_IlPgJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPT2Model\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk"
      ],
      "metadata": {
        "id": "3hrGhCtDP8_n"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Prepare data\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import re\n",
        "import torch\n",
        "# Step 1: Dataset Preparation\n",
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# load section_c data (data already cleaned)\n",
        "section_c_data_path = '/content/drive/My Drive/project_dataset/section_c_data.csv'\n",
        "df = pd.read_csv(section_c_data_path)\n",
        "df.dropna(how='any', inplace=True)\n",
        "\n",
        "# Create a new line with text and label\n",
        "new_line = {'text': 'I love you', 'label': 1}\n",
        "# Append the new line to the DataFrame\n",
        "df = df.append(new_line, ignore_index=True)\n",
        "# Create a new line with text and label\n",
        "new_line = {'text': 'I hate you', 'label': 0}\n",
        "# Append the new line to the DataFrame\n",
        "df = df.append(new_line, ignore_index=True)\n",
        "\n",
        "df = df.tail(10_000) # !!! to update df num of samples if needed !!!\n",
        "print(\"dataset size is \", df.shape[0])\n",
        "print(df.label.value_counts())\n",
        "print(df.tail(5), \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaCx6V_0Pmk6",
        "outputId": "88da0b86-8ef4-4e03-d998-5e5a1f0a5d89"
      },
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size is  10000\n",
            "0    5089\n",
            "1    4911\n",
            "Name: label, dtype: int64\n",
            "        label                                   text\n",
            "532302      0               last free travel at ap 1\n",
            "532303      0  im starting my many hours of work now\n",
            "532304      0                 i rather average 32370\n",
            "532305      1                             I love you\n",
            "532306      0                             I hate you \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-602-eae4ac7ff48e>:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(new_line, ignore_index=True)\n",
            "<ipython-input-602-eae4ac7ff48e>:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(new_line, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GPT tokenizer.\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2') #gpt2-medium\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "tokenizer.padding_side = \"left\" # Very Important\n",
        "tokenizer.bos_token='<|startoftext|>'\n",
        "tokenizer.eos_token='<|endoftext|>'\n",
        "tokenizer.pad_token='<|pad|>'"
      ],
      "metadata": {
        "id": "97nzsiYzPwtD"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3NtTXcuQGZp",
        "outputId": "f3864712-3a6b-4b61-a18b-69dd9e6dcaab"
      },
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|endoftext|> token has the id 50256\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|endoftext|> has the id 50256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2"
      ],
      "metadata": {
        "id": "0d-4P_NwQJ_o"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class GPT2Dataset(Dataset):\n",
        "\n",
        "#   def __init__(self, txt_list, labels, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "#     self.tokenizer = tokenizer\n",
        "#     self.input_ids = []\n",
        "#     self.attn_masks = []\n",
        "\n",
        "#     for txt, sentiment in zip(txt_list, labels):\n",
        "#       sentiment = \"positive\" if sentiment == 1 else \"negative\"\n",
        "#       encodings_dict = tokenizer('<|startoftext|> Q: what is the sentiment of the next sentence:\\n'+ txt + f\"\\nA: the sentence is {sentiment}. \" + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "#       self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "#       self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.input_ids)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "class GPT2Dataset(Dataset):\n",
        "    def __init__(self, txt_list, labels, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "\n",
        "        for txt, sentiment in zip(txt_list, labels):\n",
        "            sentiment_text = \"positive\" if sentiment == 1 else \"negative\"\n",
        "            max_length = 150\n",
        "            # truncated the txt\n",
        "            txt = txt[:max_length]\n",
        "            # input_text = '<|startoftext|>' + 'Q: what is the sentiment of the next text: ' + \"\\\"\" + txt +  \"\\\"\" + f\" A: the text sentiment is {sentiment_text}. \" + '<|endoftext|>'\n",
        "            # question = '<|startoftext|>' + \"\\\"\" + txt +  \"\\\"\" + ' Q: the previous quoted text was positive or negative ?' + f\" A: {sentiment_text}\" + '<|endoftext|>'\n",
        "            # txt + f\" Q: was the previous text positive or negative: A: {sentiment_text}\"\n",
        "            # input_text = '<|startoftext|>' + txt + f\" Q: was the previous text positive or negative: A: {sentiment_text}\" + ' <|endoftext|>'\n",
        "            # input_text = '<|startoftext|>' + \"\\\"\" + txt +  \"\\\"\" + f\"the classification of the previous text sentiment is {sentiment_text}\" + '<|endoftext|>'\n",
        "            # input_text = '<|startoftext|>' + \"text = \" + \"\\\"\" + txt +  \"\\\"\" + \" text sentiment = \" + f\"{sentiment_text}\" + '<|endoftext|>'\n",
        "\n",
        "            encodings_dict = self.tokenizer.encode_plus(f'\\\"{txt}\\\" Q: between positive or negative what was the sentiment of the last text ? A:',\n",
        "                                                   text_pair=f'{sentiment}',\n",
        "                                                   padding='max_length',\n",
        "                                                   truncation=True,\n",
        "                                                   max_length=max_length,\n",
        "                                                   return_tensors='pt')\n",
        "\n",
        "\n",
        "            # # Tokenize input text\n",
        "            # encodings_dict = tokenizer(input_text, truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n"
      ],
      "metadata": {
        "id": "vBD9pHEAQL5B"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bios = df.text.copy() #just use the main bio text in this example\n",
        "bios\n",
        "\n",
        "# dataset = GPT2Dataset(bios, tokenizer, max_length=768)\n",
        "# print(len(dataset))\n",
        "# train_size = int(len(dataset) * 0.8)  # 80% for training\n",
        "# print(\"train_size is \", train_size)\n",
        "# val_size = len(dataset) - train_size  # remaining for validation\n",
        "# print(\"val_size is \", val_size)\n",
        "\n",
        "# train_dataset = dataset[:train_size]  # First train_size rows for training\n",
        "# val_dataset = dataset[train_size:train_size+val_size]  # Remaining val_size rows for validation\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = GPT2Dataset(bios, df.label.copy(), tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "train_size = len(train_dataset)\n",
        "val_size = len(val_dataset)\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLJH_q-GU9Iv",
        "outputId": "62a44b1f-9462-4f74-af98-15a9db6941e1"
      },
      "execution_count": 607,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-606-3b46ac2ca372>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
            "<ipython-input-606-3b46ac2ca372>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,000 training samples\n",
            "2,000 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "5-563Bu9QY-U"
      },
      "execution_count": 608,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "# configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "configuration = GPT2Config.from_pretrained('gpt2-large', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-large', output_hidden_states=False)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "# device = torch.device(\"cuda\")\n",
        "# model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "CfoUuBaJQbtc"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 2  # !!! to update df num of epochs if needed !!!\n",
        "learning_rate = 5e-6\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "metadata": {
        "id": "s551-SNaQjo8"
      },
      "execution_count": 610,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "metadata": {
        "id": "SSYXlF5PQo2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563ea6e2-adea-46ec-9d06-1018f60da5c1"
      },
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "pqaJ5RicQr7d"
      },
      "execution_count": 612,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "JrZ88z_uQxY0"
      },
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # outputs = model(  b_input_ids,\n",
        "        #                   labels=b_labels,\n",
        "        #                   attention_mask = b_masks,\n",
        "        #                   # token_type_ids=None\n",
        "        #                 )\n",
        "        outputs = model(  input_ids = b_input_ids,\n",
        "                          attention_mask = b_masks)\n",
        "\n",
        "\n",
        "        # loss = outputs[0]\n",
        "        loss = outputs[0].mean()\n",
        "        batch_loss = loss.item()\n",
        "\n",
        "        # batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,\n",
        "                                    # top_k=50,\n",
        "                                    max_length = 1,\n",
        "                                    # top_p=0.95,\n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "\n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    prediction_labels = []\n",
        "    true_labels = []\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        # b_input_ids = batch[0].to(device)\n",
        "        # b_labels = batch[1].to(device)\n",
        "        # b_masks = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # outputs  = model(b_input_ids,\n",
        "            #                token_type_ids=None,\n",
        "            #                  attention_mask = b_masks,\n",
        "            #                 labels=b_labels)\n",
        "\n",
        "            outputs  = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                             attention_mask = b_masks)\n",
        "\n",
        "\n",
        "            loss = outputs[0].mean()\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    if avg_val_loss <= best_val_loss:\n",
        "      best_val_loss = avg_val_loss\n",
        "      print(\" current best val_acc is \", best_val_loss)\n",
        "      torch.save(model.state_dict(), '/content/drive/My Drive/project_calculations/section_c_generative_model.pth')\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-y0xgxuQzdL",
        "outputId": "43396d1e-2543-49e3-b6fe-421715489bd6"
      },
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  4,000. Loss: -25.532787322998047.   Elapsed: 0:00:18.\n",
            "0:  bipartisan vote\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  4,000. Loss: -29.171144485473633.   Elapsed: 0:00:36.\n",
            "0:  increasing damage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  4,000. Loss: -30.48090934753418.   Elapsed: 0:00:53.\n",
            "0: day.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  4,000. Loss: -31.595130920410156.   Elapsed: 0:01:11.\n",
            "0:  Hang over\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  4,000. Loss: -32.60003662109375.   Elapsed: 0:01:29.\n",
            "0:  foods that\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  4,000. Loss: -33.51179885864258.   Elapsed: 0:01:47.\n",
            "0:  trail which\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  4,000. Loss: -34.41059494018555.   Elapsed: 0:02:05.\n",
            "0: intend\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  4,000. Loss: -35.281494140625.   Elapsed: 0:02:22.\n",
            "0:  surround.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  4,000. Loss: -36.149658203125.   Elapsed: 0:02:40.\n",
            "0:  reflex for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  4,000. Loss: -36.979896545410156.   Elapsed: 0:02:58.\n",
            "0:  display the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  4,000. Loss: -37.825260162353516.   Elapsed: 0:03:15.\n",
            "0:  pastor's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  4,000. Loss: -38.6727409362793.   Elapsed: 0:03:33.\n",
            "0:  illicit for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  4,000. Loss: -39.458831787109375.   Elapsed: 0:03:51.\n",
            "0:  Liberation is\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  4,000. Loss: -40.2701530456543.   Elapsed: 0:04:09.\n",
            "0:  Nam on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  4,000. Loss: -41.053401947021484.   Elapsed: 0:04:26.\n",
            "0: ION:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  4,000. Loss: -41.8348503112793.   Elapsed: 0:04:44.\n",
            "0:  glimpse in\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  4,000. Loss: -42.613624572753906.   Elapsed: 0:05:02.\n",
            "0:  Laureat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  4,000. Loss: -43.385658264160156.   Elapsed: 0:05:20.\n",
            "0: ism and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  4,000. Loss: -44.136138916015625.   Elapsed: 0:05:38.\n",
            "0: oun by\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  4,000. Loss: -44.85908889770508.   Elapsed: 0:05:55.\n",
            "0:  election and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  4,000. Loss: -45.58262252807617.   Elapsed: 0:06:13.\n",
            "0:  crazy a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  4,000. Loss: -46.28980255126953.   Elapsed: 0:06:31.\n",
            "0:  benchs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  4,000. Loss: -46.988128662109375.   Elapsed: 0:06:49.\n",
            "0:  incorporated the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  4,000. Loss: -47.67226791381836.   Elapsed: 0:07:06.\n",
            "0: Peter,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  4,000. Loss: -48.34023666381836.   Elapsed: 0:07:24.\n",
            "0: uringly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  4,000. Loss: -48.993324279785156.   Elapsed: 0:07:42.\n",
            "0:  reproductive and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  4,000. Loss: -49.63886642456055.   Elapsed: 0:08:00.\n",
            "0:  zone in\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  4,000. Loss: -50.27234649658203.   Elapsed: 0:08:17.\n",
            "0:  commits will\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  4,000. Loss: -50.89188766479492.   Elapsed: 0:08:35.\n",
            "0:  irony and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  4,000. Loss: -51.49272918701172.   Elapsed: 0:08:53.\n",
            "0:  Sah:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  4,000. Loss: -52.09133529663086.   Elapsed: 0:09:11.\n",
            "0:  Bryan and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  4,000. Loss: -52.679710388183594.   Elapsed: 0:09:28.\n",
            "0:  spirits who\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  4,000. Loss: -53.2459602355957.   Elapsed: 0:09:46.\n",
            "0:  sees the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  4,000. Loss: -53.80069351196289.   Elapsed: 0:10:04.\n",
            "0:  hungry for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  4,000. Loss: -54.34501266479492.   Elapsed: 0:10:21.\n",
            "0:  PT in\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,600  of  4,000. Loss: -54.88267135620117.   Elapsed: 0:10:39.\n",
            "0: ün\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,700  of  4,000. Loss: -55.4044075012207.   Elapsed: 0:10:57.\n",
            "0: rucely\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,800  of  4,000. Loss: -55.921974182128906.   Elapsed: 0:11:15.\n",
            "0:  derivatives on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,900  of  4,000. Loss: -56.41462326049805.   Elapsed: 0:11:33.\n",
            "0: \u0019:\n",
            "\n",
            "  Average training loss: -43.67\n",
            "  Training epoch took: 0:11:50\n",
            "\n",
            "Running Validation...\n",
            " current best val_acc is  -57.380665481567384\n",
            "  Validation Loss: -57.38\n",
            "  Validation took: 0:00:57\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  4,000. Loss: -57.37992477416992.   Elapsed: 0:00:18.\n",
            "0:  remembering the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  4,000. Loss: -57.83955383300781.   Elapsed: 0:00:36.\n",
            "0:  Sources:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  4,000. Loss: -58.29726791381836.   Elapsed: 0:00:54.\n",
            "0: ems and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  4,000. Loss: -58.74314880371094.   Elapsed: 0:01:12.\n",
            "0: tzm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  4,000. Loss: -59.159725189208984.   Elapsed: 0:01:30.\n",
            "0: matic and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  4,000. Loss: -59.587608337402344.   Elapsed: 0:01:47.\n",
            "0:  syndi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  4,000. Loss: -59.98302459716797.   Elapsed: 0:02:05.\n",
            "0:  gamest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  4,000. Loss: -60.38078689575195.   Elapsed: 0:02:23.\n",
            "0:  injury at\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  4,000. Loss: -60.76305389404297.   Elapsed: 0:02:41.\n",
            "0: azao\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  4,000. Loss: -61.136375427246094.   Elapsed: 0:02:58.\n",
            "0:  membrane and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  4,000. Loss: -61.49033737182617.   Elapsed: 0:03:16.\n",
            "0: ijing and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  4,000. Loss: -61.82658767700195.   Elapsed: 0:03:34.\n",
            "0:  casting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  4,000. Loss: -62.172119140625.   Elapsed: 0:03:52.\n",
            "0:  purchee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  4,000. Loss: -62.489925384521484.   Elapsed: 0:04:09.\n",
            "0:  shoulders and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  4,000. Loss: -62.80255126953125.   Elapsed: 0:04:27.\n",
            "0:  built in\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  4,000. Loss: -63.096893310546875.   Elapsed: 0:04:45.\n",
            "0:  openly put\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  4,000. Loss: -63.387969970703125.   Elapsed: 0:05:02.\n",
            "0:  halted to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  4,000. Loss: -63.66062927246094.   Elapsed: 0:05:20.\n",
            "0:  Niko\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  4,000. Loss: -63.91416931152344.   Elapsed: 0:05:38.\n",
            "0:  tin and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  4,000. Loss: -64.17058563232422.   Elapsed: 0:05:56.\n",
            "0:  clinical and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  4,000. Loss: -64.40705871582031.   Elapsed: 0:06:13.\n",
            "0: lections\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  4,000. Loss: -64.63316345214844.   Elapsed: 0:06:31.\n",
            "0: els and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  4,000. Loss: -64.84575653076172.   Elapsed: 0:06:49.\n",
            "0: lab can\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  4,000. Loss: -65.0422592163086.   Elapsed: 0:07:07.\n",
            "0:  triple the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  4,000. Loss: -65.23588562011719.   Elapsed: 0:07:24.\n",
            "0: 220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  4,000. Loss: -65.41343688964844.   Elapsed: 0:07:42.\n",
            "0:  See no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  4,000. Loss: -65.57115936279297.   Elapsed: 0:08:00.\n",
            "0: @@:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  4,000. Loss: -65.7311019897461.   Elapsed: 0:08:18.\n",
            "0:  host from\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  4,000. Loss: -65.86400604248047.   Elapsed: 0:08:35.\n",
            "0: role and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  4,000. Loss: -65.99971771240234.   Elapsed: 0:08:53.\n",
            "0: iacs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  4,000. Loss: -66.10763549804688.   Elapsed: 0:09:11.\n",
            "0:  LD:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  4,000. Loss: -66.21521759033203.   Elapsed: 0:09:29.\n",
            "0:  Listen:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  4,000. Loss: -66.30842590332031.   Elapsed: 0:09:47.\n",
            "0:  dyx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  4,000. Loss: -66.38451385498047.   Elapsed: 0:10:04.\n",
            "0:  Domestic is\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  4,000. Loss: -66.45590209960938.   Elapsed: 0:10:22.\n",
            "0:  beneficiaries have\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,600  of  4,000. Loss: -66.51478576660156.   Elapsed: 0:10:40.\n",
            "0:  Title to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,700  of  4,000. Loss: -66.55195617675781.   Elapsed: 0:10:58.\n",
            "0:  μs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,800  of  4,000. Loss: -66.58372497558594.   Elapsed: 0:11:15.\n",
            "0:  selling so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,900  of  4,000. Loss: -66.60218048095703.   Elapsed: 0:11:33.\n",
            "0:  migrant:\n",
            "\n",
            "  Average training loss: -63.36\n",
            "  Training epoch took: 0:11:51\n",
            "\n",
            "Running Validation...\n",
            " current best val_acc is  -67.00326395416259\n",
            "  Validation Loss: -67.00\n",
            "  Validation took: 0:01:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:25:38 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Display floats with two decimal places.\n",
        "# pd.set_option('precision', 2)\n",
        "\n",
        "# Set the precision option\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "wIlausZQQ62x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "55165a6e-e488-423c-e01c-f890b1c0ef65"
      },
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1             -43.67       -57.38       0:11:50         0:00:57\n",
              "2             -63.36       -67.00       0:11:51         0:01:00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90cac1b3-6f5c-40cf-9be8-428c8c1efe74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-43.67</td>\n",
              "      <td>-57.38</td>\n",
              "      <td>0:11:50</td>\n",
              "      <td>0:00:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-63.36</td>\n",
              "      <td>-67.00</td>\n",
              "      <td>0:11:51</td>\n",
              "      <td>0:01:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90cac1b3-6f5c-40cf-9be8-428c8c1efe74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90cac1b3-6f5c-40cf-9be8-428c8c1efe74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90cac1b3-6f5c-40cf-9be8-428c8c1efe74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 615
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(df_stats).to_csv('/content/drive/My Drive/project_calculations/section_c_all_loss.csv', index=False)\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EgfNWK59REi7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "bc9b3b52-47b7-4c33-b56c-28200736d65b"
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "HKd6r7RORIKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b87d5aa-e6eb-4c89-d373-2d77fd3d5eb9"
      },
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 436 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50257, 1280)\n",
            "transformer.wpe.weight                                  (1024, 1280)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                  (1280,)\n",
            "transformer.h.0.ln_1.bias                                    (1280,)\n",
            "transformer.h.0.attn.c_attn.weight                      (1280, 3840)\n",
            "transformer.h.0.attn.c_attn.bias                             (3840,)\n",
            "transformer.h.0.attn.c_proj.weight                      (1280, 1280)\n",
            "transformer.h.0.attn.c_proj.bias                             (1280,)\n",
            "transformer.h.0.ln_2.weight                                  (1280,)\n",
            "transformer.h.0.ln_2.bias                                    (1280,)\n",
            "transformer.h.0.mlp.c_fc.weight                         (1280, 5120)\n",
            "transformer.h.0.mlp.c_fc.bias                                (5120,)\n",
            "transformer.h.0.mlp.c_proj.weight                       (5120, 1280)\n",
            "transformer.h.0.mlp.c_proj.bias                              (1280,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                      (1280,)\n",
            "transformer.ln_f.bias                                        (1280,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short sanity check\n",
        "\n",
        "model.eval()\n",
        "def generate_response(question):\n",
        "    # Encode the question\n",
        "    input_ids = tokenizer.encode(question, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate the response\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=100,\n",
        "        num_return_sequences=1,\n",
        "        attention_mask=input_ids.ne(tokenizer.pad_token_id).to(device),\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated response\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n",
        "# Example usage\n",
        "txt = \"i love you\"\n",
        "# question = '<|startoftext|> answer in one word\\nQ: what is the sentiment of the next sentence:\\n'+ txt + f\"\\nA: the sentence is \" + '<|endoftext|>'\n",
        "# question = txt + '\\n Q: was the previous text positive or negative: ' + \"\\nA:\"\n",
        "# question = \"text = \" + \"\\\"\" + txt +  \"\\\"\" + \"text sentiment = \"\n",
        "# input_text = '<|startoftext|>' + 'Q: what is the sentiment of the next text: ' + \"\\\"\" + txt +  \"\\\"\" + f\" A: the text sentiment is {sentiment_text}. \" + '<|endoftext|>'\n",
        "# question =  \"\\\"\" + txt +  \"\\\"\" + ' Q: positive or negative: ' + \" A: \"\n",
        "      #  encodings_dict = self.tokenizer.encode_plus(f'Q: what is the sentiment of the next text: \\\"{txt}\\\"\\nA:',\n",
        "\n",
        "question = f'\\\"{txt}\\\" Q: between positive or negative what was the sentiment of the last text ? A:'\n",
        "response = generate_response(question)\n",
        "# response= response.split()[-1]\n",
        "print(f\"{question}\\n{response}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# tokenizer.padding_side = \"left\" # Very Important\n",
        "# tokenizer.bos_token='<|startoftext|>'\n",
        "# tokenizer.eos_token='<|endoftext|>'\n",
        "# tokenizer.pad_token='<|pad|>'\n",
        "# input_text = '<|startoftext|>' + txt + '\\n Q: was the previous text positive or negative:\\n' + f\"\\nA: {sentiment_text}. \" + ' <|endoftext|>'\n",
        "\n",
        "txt = \"I hate you\"\n",
        "# question = txt + ' Q: was the previous text positive or negative: ' + \" A: \"\n",
        "question = f'Q: between positive or negative what is the sentiment of the next text: \\\"{txt}\\\" A:'\n",
        "response = generate_response(question)\n",
        "# response = response.split()[-1]\n",
        "print(f\"{question}\\n{response}\")"
      ],
      "metadata": {
        "id": "jKstCZXvd6WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f490c48-5736-41d6-a3cc-128bf2a84f1d"
      },
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"i love you\" Q: between positive or negative what was the sentiment of the last text ? A:\n",
            "\"i love you\" Q: between positive or negative what was the sentiment of the last text? A: the last text was a text that was a text that was a text that was a text that was a text that was a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and a and\n",
            "\n",
            "\n",
            "Q: between positive or negative what is the sentiment of the next text: \"I hate you\" A:\n",
            "Q: between positive or negative what is the sentiment of the next text: \"I hate you\" A: the text is a negative and the text is a positive and the text is a negative and the text is a positive and the text is a negative and the text is a positive and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        }
      ]
    }
  ]
}