{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNVoXWaDWDOkoY0gBUwDhX8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinon2592/DL_Project_046211/blob/main/section_c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/my-drive/project_calculations')\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M-WYp00bZf4q",
        "outputId": "ba9b937d-08a1-4fb6-8fce-f032a6a3182f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F\n",
        "import csv"
      ],
      "metadata": {
        "id": "b3Ki4oYpS6R3",
        "outputId": "c7988b4c-2d10-4bdd-85dd-f6aa94cbd436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FcpxAucxnqU",
        "outputId": "f21cab75-f07c-404e-8fe7-2101b4f2a245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size is  100\n",
            "1    51\n",
            "0    49\n",
            "Name: label, dtype: int64\n",
            "        label                                               text\n",
            "506952      0                                                NaN\n",
            "299056      1       video is coming along good the intro is done\n",
            "45979       0  i leave friday i don t know what lydia is doin...\n",
            "368636      0  really trying out kde 4 for the first time lov...\n",
            "103692      0  neck hurts from a hard ass wreck wakin today n... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Prepare data\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import re\n",
        "import torch\n",
        "# Step 1: Dataset Preparation\n",
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# load section_c data (data already cleaned)\n",
        "section_c_data_path = '/content/drive/My Drive/project_dataset/section_c_data.csv'\n",
        "df = pd.read_csv(section_c_data_path)\n",
        "df = df.sample(100, random_state=1)\n",
        "print(\"dataset size is \", df.shape[0])\n",
        "print(df.label.value_counts())\n",
        "print(df.sample(5), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Texts(Dataset):\n",
        "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
        "\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "        self.texts = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "          label = row['label']\n",
        "          sentiment = 'positive' if label == 1 else 'negative'\n",
        "          text = row['text'].split()\n",
        "          text.insert(0, f\"Considering positive or negative sentiment, the following sentence is classified as {sentiment}. \")\n",
        "          self.texts.append(torch.tensor(\n",
        "                self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n",
        "            ))\n",
        "        if truncate:\n",
        "            self.texts = self.texts[:20000]\n",
        "        self.texts_count = len(self.texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.texts_count\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.texts[item]\n",
        "\n",
        "df.dropna(how='any', inplace=True)\n",
        "dataset = Texts(df['text'], truncate=False, gpt2_type=\"gpt2\")"
      ],
      "metadata": {
        "id": "nCZe-ctbx1Tr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "load_model_parameters = False\n",
        "model_path = '/content/drive/My Drive/project_calculations/generative_model.pth'\n",
        "if os.path.exists(model_path) and load_model_parameters:\n",
        "  print(\"loading last model parameters..\")\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "#Accumulated batch size (since GPT2 is so big)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ],
      "metadata": {
        "id": "jcN5Ynbix8RS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    dataset, model, tokenizer,\n",
        "    batch_size=16, epochs=2, lr=2e-5,\n",
        "    max_seq_len=400, warmup_steps=200,\n",
        "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
        "    test_mode=False,save_model_on_epoch=False,\n",
        "):\n",
        "    acc_steps = 100\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    # device=torch.device(\"cuda\")\n",
        "    # model = model.cuda()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "      total_loss = []\n",
        "      for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "          (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "\n",
        "          if carry_on and idx != len(train_dataloader) - 1:\n",
        "              continue\n",
        "\n",
        "          input_tensor = input_tensor.to(device)\n",
        "          outputs = model(input_tensor, labels=input_tensor)\n",
        "          loss = outputs[0]\n",
        "          total_loss.append(loss)\n",
        "          loss.backward()\n",
        "\n",
        "          if (accumulating_batch_count % batch_size) == 0:\n",
        "              optimizer.step()\n",
        "              scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "              model.zero_grad()\n",
        "\n",
        "          accumulating_batch_count += 1\n",
        "          input_tensor = None\n",
        "      if save_model_on_epoch and loss < best_loss:\n",
        "        best_loss = loss\n",
        "        print(\"bset loss so far is \", best_loss)\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/project_calculations/generative_model.pth')\n",
        "      print(f\"Training epoch {epoch} , Train Loss: {torch.tensor(total_loss).mean():.3f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "XFeTIWr1x9WC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(dataset=dataset, model=model, tokenizer=tokenizer, save_model_on_epoch=False, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSfDp3SLC3i9",
        "outputId": "8e633847-c7c1-4dff-fb58-a369d39fd8f1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "99it [00:02, 39.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 0 , Train Loss: 2.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "99it [00:03, 26.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1 , Train Loss: 2.630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "99it [00:02, 38.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 2 , Train Loss: 2.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}